//
// Weka classifier interface for CaMML/CDMS
//
// Copyright (C) 2002-2005 Rodney O'Donnell.  All Rights Reserved.
// Weka option implementation written by Luke Hope (C) 2006 Monash University.
//
// Source formatted to 100 columns.
// 4567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890

// File: CammlClassifier.java
// Author: {rodo,lhope}@csse.monash.edu.au

package camml.plugin.weka;

import java.util.Vector;
import java.util.Enumeration;
import java.io.*;

import weka.core.*;
import weka.classifiers.*; 

import camml.plugin.weka.Converter;

import cdms.core.*;
import camml.core.models.ModelLearner;
import camml.core.models.bNet.*;
import camml.core.search.SearchPackage;

import weka.filters.supervised.attribute.Discretize;
import weka.filters.unsupervised.attribute.ReplaceMissingValues;

/**
 * Class to interface with the java version of Camml.
 *
 * Learn a Bayes Net from data.
 * 
 * @author Luke Hope <lhope@csse.monash.edu.au>
 * @version $Revision: 1.2 $ $Date: 2006/09/13 09:58:44 $
 * $Source: /u/csse/public/bai/bepi/cvs/CAMML/Camml/camml/plugin/weka/CaMMLClassifier.java,v $
 */
public class CaMMLClassifier extends Classifier
{
    /** 
	ModelLearner function used in this classifier.
     */
    protected ModelLearner modelLearner;
	
    /** Model generated by modelLearner */
    protected Value.Model model = null;
	
    /** parameters generated by modelLearner */
    protected Value params = null;
	
    /**
     * Filter to discretize missing values.  This is initialised in buildClassifier. <br>
     * If the instances passed to buildClassifier have a discrete target attribute MDL is used for
     *  optimal binning.  If not a less intelligent method bins each attribute into 10 bins.
     */
    protected Discretize discreteFilter;
    //protected DiscretizeFilter discreteFilter;
	
    /**
     * missingFilter replaces each missing value with the mode likely value for that attribute.
     */
    protected ReplaceMissingValues missingFilter;
    //protected ReplaceMissingValuesFilter missingFilter;
	
    /**
     * A replacement for <code>/dev/null</code>
     *
     * This is to shut off CaMML's outputs when not in debug mode.
     */
    protected class DevNull extends OutputStream
    {
	/**
	 * Does nothing with the specified byte.
	 *
	 * @param      b the <code>byte</code> to ignore.
	 * @exception  IOException  if an I/O error occurs.
	 */
	public void write(int b) throws IOException
	{ }
    }

   /**********************************
     * WEKA OPTION HANDLING VARIABLES *
     **********************************/
    
    protected boolean verbose = false;

    /**
       cpdLearner is the ModelLearner responsible for coding the
       conditional probability distributions in network nodes.  It
       defaults to a table encoding.
    */
    protected ModelLearner cpdLearner = camml.core.models.cpt.CPTLearner.mmlAdaptiveCPTLearner;

    /** A string representing the encoding options. Defaults to "cpt". */
    protected String encoding = "cpt";

    protected boolean weightedAverage = false;

    /** The default arc probability (0.5) */
    public final double ARC_DEFAULT = 0.5;

    protected double arcProbability = ARC_DEFAULT;

    protected double searchMultiplier = 1.0;

    /** The default temperature (1.0) */
    public final double TEMP_DEFAULT = 1.8;

    protected double temperature = TEMP_DEFAULT;

    protected String priors = "";

    /**********************************/

    /** ModelLearnerClassifier constructor simply sets modelLearner variable */
    public CaMMLClassifier() {
	super();
    }

    /**
     * Initialize filters based on instances provided.  <br>
     * NOTE: This function does NOT actually do the filtering
     */
    public void initializeFilters( Instances instances ) throws Exception
    {
	// Initialise the discrete filter.
	discreteFilter = new Discretize();
	//discreteFilter = new DiscretizeFilter();
	if ( (instances.classIndex() == -1) || (!instances.classAttribute().isNominal()) ) {
	    //discreteFilter.setUseMDL(false);
	}
	else {	    
	    discreteFilter.setUseBetterEncoding(true);
	}	
	discreteFilter.setInputFormat(instances);
		
	// We need this to get the correct output input format into missingFilter
	Instances temp = weka.filters.Filter.useFilter( new Instances(instances), discreteFilter );
		
		
	// Initialise and run the missing value filter.
	missingFilter = new ReplaceMissingValues();
	//missingFilter = new ReplaceMissingValuesFilter();
	missingFilter.setInputFormat( temp );
    }
	
    /** return a copy of instances with discrete and missingValue filters applied to it. */
    public Instances filterInstances( Instances instances ) throws Exception
    {
	Instances instancesCopy = new Instances( instances );
	instancesCopy =  weka.filters.Filter.useFilter( instancesCopy, discreteFilter );
	instancesCopy = weka.filters.Filter.useFilter( instancesCopy, missingFilter );
	return instancesCopy;
    }

    /** 
     * Generates the ModelLearner using the options.  encoding and
     * weightedAverage are set directly, and other options are set via
     * BNetSearch.setOption(java.lang.String option, Value v)
     */
    protected ModelLearner generateLearner() {
	BNetLearner learner =
	    new BNetLearner( SearchPackage.mlCPTLearner, cpdLearner, weightedAverage, false);

	// rest of configuration here.	
	Vector options = new Vector(); // string
	Vector values = new Vector(); // Value

	// switch on Netica.
	options.add("useNetica");
	values.add(new Value.Discrete(0));
	
	// Note, arcProbability must come BEFORE priors, because priors locks it in.
	if(arcProbability != ARC_DEFAULT) {
	    options.add("arcProb");
	    values.add(new Value.Continuous(arcProbability));
	}

	if(searchMultiplier != 1.0) {
	    options.add("searchFactor");
	    values.add(new Value.Continuous(searchMultiplier));
	}

	if(temperature != TEMP_DEFAULT) {
	    options.add("temperature");
	    values.add(new Value.Continuous(temperature));
	}

	// Note, priors must come AFTER arcProbability, as any further changes will be ignored.
	if(!priors.equals("")) {
	    try { 
		File file = new File(priors);
		// Ignoring a very strange case where the text for setting the prior is the same as a filename.
		if(file.canRead()) { // if it's a file

		    BufferedReader in = 
			new BufferedReader(new InputStreamReader(new FileInputStream(file)));
		    StringBuffer buf = new StringBuffer();
		    String line;
		    
		    while((line = in.readLine()) != null) {
			buf.append(line);
			buf.append('\n');
		    }

		    values.add(new Value.Str(buf.toString()));
		    
		}
		else // if it's set on the command line.
		    { values.add(new Value.Str(priors)); }

		// this is in the try so if there is a failure in the values the whole TomPrior gets ignored.
		options.add("TOMPrior");
	    } catch(java.io.IOException e)
		{ e.printStackTrace(); }
	}
	
	// convert the option vectors here.
	if(options.size() > 0) { 
	    String[] optionArray = new String[options.size()];
	    Value[] valueArray = new Value[values.size()];
	    learner.setOptions((String[])options.toArray(optionArray), (Value[])values.toArray(valueArray));
	}
	
	return learner;
    }	
	
    /**
     * Use the modelLearner to build the classifier.
     *
     * @param instances set of instances serving as training data 
     * @exception Exception if the classifier has not been generated 
     * successfully
     */
    public synchronized void buildClassifier(Instances instances) throws Exception {

	PrintStream stdOut = System.out;
	if(!verbose) 
	    { System.setOut(new PrintStream(new DevNull(), true)); }

	// generate learner based on the options
	modelLearner = generateLearner();

	// Set up data for Camml
	initializeFilters( instances );
	Instances instancesCopy = filterInstances( instances  );
	Value.Vector data = Converter.instancesToVector( instancesCopy );
		
		
		
	Value.Structured msy = modelLearner.parameterize( Value.TRIV, data, data );	
	this.model = (Value.Model)msy.cmpnt(0);
		
	// Netica does significantly faster/more accurate inference than my stochastic algorithm.
	//  so if the model returnes is stochastic, convert it to Netica's exact method.
	if ( this.model instanceof BNetStochastic ) {
 	    Type.Structured dataType = (Type.Structured)((Type.Model)this.model.t).dataSpace;
 	    this.model = new camml.plugin.netica.BNetNetica( dataType );
 	}
		
	this.params = msy.cmpnt(2);

	// restore standard out.
	System.setOut(stdOut);
    }
	
	
	
    /**
     * Calculates the class membership probabilities for the given test 
     * instance.
     *
     * @param instance the instance to be classified
     * @return predicted class probability distribution
     * @exception Exception if there is a problem generating the prediction
     */
    public double [] distributionForInstance(Instance instance) 
	throws Exception { 
		
	// Apply discreteFilter to instance.
	// NOTE: Missing value filter is NOT required as Bayes Networks can cope with missing vals.
	discreteFilter.input( instance );
	Instance filteredInstance = discreteFilter.output( );
		
		
		
	int classVariable = filteredInstance.classAttribute().index();
		
	Value.Structured instanceStruct = Converter.instanceToStruct( filteredInstance );
	Type.Structured sType = ((Type.Structured)instanceStruct.t);
	Type[] type = sType.cmpnts;
	String[] nameArray = sType.labels;
	Type.Discrete classType = (Type.Discrete)type[classVariable];
	int arity = (int)classType.UPB - (int)classType.LWB + 1;	
		
	Value[] inputArray = new Value[instanceStruct.length()];
	Value[][] outputArray = new Value[arity][instanceStruct.length()];
		
		
	// Loop through each variable in order.
	for ( int i = 0; i < inputArray.length; i++ ) {
			
	    // Input of target variable is missing, output is set to each possible value to create
	    // a multistate distribution.
	    if ( i == classVariable ) {
		inputArray[i] = new Value.Discrete( (Type.Discrete)type[i], 
						    Value.S_UNOBSERVED, 0 );
		for ( int j = 0; j < arity; j++ ) {
		    outputArray[j][i] = new Value.Discrete( (Type.Discrete)type[i],
							    Value.S_PROPER, 
							    (int)classType.LWB + j );
		}
	    }
	    // Missing values are missing on both input and output.
	    else if ( filteredInstance.isMissing(i) ) {
		inputArray[i] = new Value.Discrete( (Type.Discrete)type[i], Value.S_UNOBSERVED, 0 );
		for ( int j = 0; j < arity; j++ ) {
		    outputArray[j][i] = inputArray[i];
		}
				
	    }
	    // Regular values are present in both input and output.
	    else {
		inputArray[i] = instanceStruct.cmpnt(i);
		for ( int j = 0; j < arity; j++ ) {
		    outputArray[j][i] = instanceStruct.cmpnt(i);
		}
	    }
	}
		
	Value.Structured input = new Value.DefStructured( inputArray, nameArray );
	Value.Structured[] output = new Value.Structured[arity];
	for ( int i = 0; i < output.length; i++ ) {
	    output[i] = new Value.DefStructured( outputArray[i], nameArray );
	}
		
		
	double[] prob = new double[arity];
	for ( int i = 0; i < prob.length; i++ ) {
	    prob[i] = Math.exp( model.logP( output[i], params, input ) );
	}
		
	return prob;
		
    }
	
    public String toString()
    {
	if ( model instanceof camml.plugin.netica.BNetNetica ) {
	    camml.plugin.netica.BNetNetica bNet = (camml.plugin.netica.BNetNetica)model;	    
	    return bNet.toString( (Value.Vector)params, "NET_TITLE","COMMENT" );
	}
	else if ( model instanceof BNet ) {
	    return ((BNet)model).makeString( (Value.Vector)params );
	}
	else return "(" + model + "," + params + ")";
    }

    /********************************************************
     * The main method to evaluate the model.
     * Calls weka.classifiers.Evaluation.evaluateModel 
     * on CaMMLWrapper.
     *********************************************************/
    public static void main(String [] argv) {
        try {
            System.out.println(Evaluation.evaluateModel(new CaMMLClassifier(), argv));
        } catch (Exception e)
            { e.printStackTrace(); }
    }



    /************************************
     *
     * Option Handling Routines
     *
     ************************************/

    public String globalInfo() {
	return "The Causal MML (CaMML) Bayesian Network classifier."
	    + " CaMML generates a Bayesian Network using"
	    + " a Metropolis search through the space of causal (Bayesian) models, guided"
	    + " by a Minimum Message Length (MML) scoring metric. MML is related to MDL and"
	    + " jointly scores the model and the fit of the data to the model.  CaMML does"
	    + " does not directly support numeric variables, but discretizes them using"
	    + " Weka's MDL discretizer (or optionally, a fixed number of bins)."
	    + " It corrently deals with missing values in the training set by removing all"
	    + " instances with them, which we regard as a bug."
	    + "\n"
	    + " See also:\n"
	    + "  *  K.B. Korb and A.N. Nicholson 2003. <i>Bayesian Artificial Intelligence</i>."
	    + " CRC Press. Esp. 207--217.\n"
	    + "  *  C.S. Wallace and K.B. Korb 1999. Learning linear causal models by MML sampling."
	    + " In A. Gammerman, <i>Causal Models and Intelligent Data Management</i>"
	    + " 89--111 Springer-Verlag\n"
	    + " For more references and information, visit the website:\n"
	    + "  *  http://www.datamining.monash.edu.au/software/camml\n";
    }

    /**
     * Returns an enumeration describing the available options
     *
     * @return an enumeration of all the available options
     */
    public Enumeration listOptions() {
	
        Vector newVector = new Vector();

        newVector.addElement(new Option("\t" + verboseTipText(),
                                        "V", 0,"-V"));

        newVector.addElement(new Option("\t" + encodingTipText(),
					"E", 1, "-E"));

	newVector.addElement(new Option("\t" + weightedAverageTipText(),
					"W", 0, "-W"));

	newVector.addElement(new Option("\t" + arcProbabilityTipText(),
					"A", 1, "-A"));

	newVector.addElement(new Option("\t" + searchMultiplierTipText(),
					"M", 1, "-M"));

	newVector.addElement(new Option("\t" + temperatureTipText(),
					"T", 1, "-T"));

	newVector.addElement(new Option("\t" + priorsTipText(),
					"P", 1, "-P"));
	
        return newVector.elements();
    }
    
    /**
     * Parses a given list of options.
     *
-E 
Specify the node encoding (one or more of cpt,dtree,logit,all). More
than one means use the best encoding on a node by node basis.
cpt - encode as a conditional probability table.
dtree - encode as a decision tree.
logit - encode as a logistical model.
all - encode as best of all three.
Fastest and default is cpt, all gets the best results.
-W
	Use a weighted average of models to predict instead of the single best one.
-A
	Set the a priori probability of an arc between any two nodes (defaults to 0.5).
-M
	Multiply the standard search by the given factor.Less than one is faster, greater than one is slower.
-T
	Fix the temperature at a set value (defaults to 1.0).
     * @param options the list of options as an array of strings
     * @exception Exception if an option is not supported
     */
    public void setOptions(String[] options) throws Exception {

        setVerbose(Utils.getFlag('V', options));
	
        setEncoding(Utils.getOption('E', options));

	setWeightedAverage(Utils.getFlag('W', options));
	
	try 
	    { setArcProbability(Double.parseDouble(Utils.getOption('A', options))); }
	catch(NumberFormatException e) {}

	try 
	    { setSearchMultiplier(Double.parseDouble(Utils.getOption('M', options))); }
	catch(NumberFormatException e) {}

	try 
	    { setTemperature(Double.parseDouble(Utils.getOption('T', options))); }
	catch(NumberFormatException e) {}

	setPriors(Utils.getOption('P', options));

        Utils.checkForRemainingOptions(options);
    }

    
    
    /**
     * Gets the current settings of the classifier.
     *
     * @return an array of strings suitable for passing to setOptions
     */
    public String [] getOptions() {
	
        String [] options = new String [7];
        int current = 0;
	
	if(verbose)
	    { options[current++] = "-V"; }

	options[current++] = "-E " + encoding;

	if(weightedAverage)
	    { options[current++] = "-W"; }

	if(arcProbability != ARC_DEFAULT)
	    { options[current++] = "-A " + arcProbability; }

	if(searchMultiplier != 1.0)
	    { options[current++] = "-M " + searchMultiplier; }

	if(temperature != TEMP_DEFAULT)
	    { options[current++] = "-T " + temperature; }

	// I have a feeling that additional quoting might be needed.
	if(!priors.equals(""))
	    { options[current++] = "-P\" " + "\"" + priors; } 

        while (current < options.length) {
            options[current++] = "";
        }
        return options;
    }

    public String verboseTipText() {
	return "Print progress indicators and other information to standard output.";
    }

    public boolean getVerbose() {
	return verbose;
    }

    public void setVerbose(boolean newval) {
	verbose = newval;
    }

    public String encodingTipText() {
	return "Specify the node encoding (one or more of cpt,dtree,logit,all)."
	    + " More than one means use the best encoding on a node by node basis.\n"
	    + "cpt - encode as a conditional probability table.\n"
	    + "dtree - encode as a decision tree.\n"
	    + "logit - encode as a logistical model.\n"
	    + "all - encode as best of all three.\n"
	    + "Fastest and default is cpt, all gets the best results.";
    }

    public void setEncoding(String e) {
	e = e.toLowerCase();

	if(e.contains("all")) {
	    encoding = "all";
	    cpdLearner = camml.core.models.dual.DualLearner.dualCPTDTreeLogitLearner; 
	}
	else {
	    boolean c = e.contains("cpt");
	    boolean d = e.contains("dtree");
	    boolean l = e.contains("logit");
	    if(c) {
		if(d) {
		    if(l) {
			encoding = "all";
			cpdLearner = camml.core.models.dual.DualLearner.dualCPTDTreeLogitLearner; 
		    }
		    else {
			encoding = "cpt,dtree";
			cpdLearner = camml.core.models.dual.DualLearner.dualCPTDTreeLearner;
		    }
		}
		else if(l) {
		    encoding = "cpt,logit";
		    cpdLearner = camml.core.models.dual.DualLearner.dualCPTLogitLearner; 
		}
		else {
		    encoding = "cpt";
		    cpdLearner = camml.core.models.cpt.CPTLearner.mmlAdaptiveCPTLearner;
		}
	    }
	    else if(d) {
		if(l) {
		    encoding = "dtree,logit";
		    cpdLearner = camml.core.models.dual.DualLearner.dualDTreeLogitLearner; 
		}
		else {
		    encoding = "dtree";
		    cpdLearner =
			camml.core.models.dTree.ForcedSplitDTreeLearner.multinomialDTreeLearner;
		}
	    }
	    else if(l) {
		encoding = "logit";
		cpdLearner = camml.core.models.logit.LogitLearner.logitLearner;
	    }
	    else {
		encoding = "cpt";
		cpdLearner = camml.core.models.cpt.CPTLearner.mmlAdaptiveCPTLearner;
	    }
	}
    }
	       
    public String getEncoding() {
	return encoding;
    }

    public String weightedAverageTipText() {
	return "Use a weighted average of models to predict instead of the single best one.";
    }

    public boolean getWeightedAverage() {
	return weightedAverage;
    }

    public void setWeightedAverage(boolean newval) {
	weightedAverage = newval;
    }

    public String arcProbabilityTipText() {
	return "Set the a priori probability of an arc between any two nodes (defaults to " + ARC_DEFAULT + ").";
    }

    public void setArcProbability(double newval) {
	arcProbability = newval;
    }

    public double getArcProbability() {
	return arcProbability;
    }

    public String searchMultiplierTipText() {
	return "Multiply the standard search by the given factor."
	    + "Less than one is faster, greater than one is slower.";
    }

    public void setSearchMultiplier(double newval) {
	searchMultiplier = newval;
    }

    public double getSearchMultiplier() {
	return searchMultiplier;
    }

    // todo a better description.
    public String temperatureTipText() {
	return "Set the monte-carlo search temperature (defaults to " + TEMP_DEFAULT + ").";
    }

    public void setTemperature(double newval) {
	temperature = newval;
    }

    public double getTemperature() {
	return temperature;
    }

    // todo a better description.
    public String priorsTipText() {
	return "Set a prior probability over the modelspace using either a filename or"
	    + " on the command line. (See camml.plugin.tomCoster.ExpertElicitedTOMCoster for more info.)";
    }
    
    public void setPriors(String newval) {
	priors = newval;
    }

    public String getPriors() {
	return priors;
    }
}


